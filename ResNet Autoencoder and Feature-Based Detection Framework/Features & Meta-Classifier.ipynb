{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11058666,"sourceType":"datasetVersion","datasetId":6890034},{"sourceId":11814705,"sourceType":"datasetVersion","datasetId":7420780},{"sourceId":385332,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":317894,"modelId":338461},{"sourceId":392557,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":323213,"modelId":343960}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:06:46.718680Z","iopub.execute_input":"2025-05-14T20:06:46.718914Z","iopub.status.idle":"2025-05-14T20:06:54.671055Z","shell.execute_reply.started":"2025-05-14T20:06:46.718886Z","shell.execute_reply":"2025-05-14T20:06:54.670175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install scikit-image pywavelets umap-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:06:54.672035Z","iopub.execute_input":"2025-05-14T20:06:54.672459Z","iopub.status.idle":"2025-05-14T20:06:58.962504Z","shell.execute_reply.started":"2025-05-14T20:06:54.672409Z","shell.execute_reply":"2025-05-14T20:06:58.961644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport pywt\nfrom skimage.feature import graycomatrix, graycoprops\nfrom skimage.measure import regionprops, label\nfrom scipy.stats import skew, kurtosis\nimport umap\nfrom sklearn.metrics.pairwise import cosine_distances\nfrom tensorflow.keras.models import load_model, Model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    f1_score, accuracy_score, precision_score, recall_score\n)\nfrom sklearn.covariance import EmpiricalCovariance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:06:58.964704Z","iopub.execute_input":"2025-05-14T20:06:58.964915Z","iopub.status.idle":"2025-05-14T20:07:32.260642Z","shell.execute_reply.started":"2025-05-14T20:06:58.964896Z","shell.execute_reply":"2025-05-14T20:07:32.259883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAIN_GEN_DIR    = \"/kaggle/input/gan-train-data/ImageCLEF25_GAN_Detect_Training_Data_Usage_training-dataset/generated\"\nTRAIN_REAL_USED  = \"/kaggle/input/gan-train-data/ImageCLEF25_GAN_Detect_Training_Data_Usage_training-dataset/real_used\"\nTRAIN_REAL_UNUSED= \"/kaggle/input/gan-train-data/ImageCLEF25_GAN_Detect_Training_Data_Usage_training-dataset/real_not_used\"\nTEST_REAL_UNKNOWN= \"/kaggle/input/gan-test-data/real_unknown\"\nTEST_GEN_DIR     = \"/kaggle/input/gan-test-data/generated\"\n\nIMG_SIZE = (128,128)\n\ndef load_and_preprocess(folder):\n    imgs = []\n    for fn in os.listdir(folder):\n        im = load_img(os.path.join(folder, fn), target_size=IMG_SIZE)\n        im = img_to_array(im)/255.0\n        imgs.append(im.astype(np.float32))\n    return np.stack(imgs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:07:32.261503Z","iopub.execute_input":"2025-05-14T20:07:32.261922Z","iopub.status.idle":"2025-05-14T20:07:32.266882Z","shell.execute_reply.started":"2025-05-14T20:07:32.261894Z","shell.execute_reply":"2025-05-14T20:07:32.266080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_synth_train = load_and_preprocess(TRAIN_GEN_DIR)\nX_real_used   = load_and_preprocess(TRAIN_REAL_USED)\nX_real_unused = load_and_preprocess(TRAIN_REAL_UNUSED)\nX_real_unknown= load_and_preprocess(TEST_REAL_UNKNOWN)\n\nautoencoder = load_model('/kaggle/input/resnet_encoder_2/keras/default/1/autoencoder_model_test_train.keras')\nencoder = Model(\n    inputs=autoencoder.input,\n    outputs=autoencoder.get_layer('latent').output\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:07:32.268092Z","iopub.execute_input":"2025-05-14T20:07:32.268397Z","iopub.status.idle":"2025-05-14T20:07:59.423719Z","shell.execute_reply.started":"2025-05-14T20:07:32.268370Z","shell.execute_reply":"2025-05-14T20:07:59.423137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_radiomic_features(img):\n    gray = cv2.cvtColor((img*255).astype(np.uint8), cv2.COLOR_BGR2GRAY)\n    vals = gray.ravel()\n    feats = {\n        'mean': np.mean(vals), 'var': np.var(vals),\n        'skew': skew(vals), 'kurtosis': kurtosis(vals)\n    }\n    glcm = graycomatrix(gray, distances=[1],\n                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n                        levels=256, symmetric=True, normed=True)\n    for prop in ['contrast','correlation','energy','homogeneity']:\n        arr = graycoprops(glcm, prop).ravel()\n        for i,v in enumerate(arr):\n            feats[f'glcm_{prop}_{i}'] = v\n    return feats\n\ndef extract_gabor_features(img, frequencies=[0.1,0.3,0.5], thetas=[0, np.pi/4, np.pi/2]):\n    \"\"\"Apply a bank of Gabor filters and return mean & var of responses.\"\"\"\n    gray = cv2.cvtColor((img*255).astype(np.uint8), cv2.COLOR_BGR2GRAY)\n    feats = {}\n    for freq in frequencies:\n        for theta in thetas:\n            kern = cv2.getGaborKernel((21,21), sigma=4.0, theta=theta,\n                                      lambd=1/freq, gamma=0.5, psi=0)\n            resp = cv2.filter2D(gray, cv2.CV_32F, kern)\n            feats[f'gabor_mean_f{freq:.2f}_t{theta:.2f}'] = np.mean(resp)\n            feats[f'gabor_var_f{freq:.2f}_t{theta:.2f}']  = np.var(resp)\n    return feats\n\ndef extract_wavelet_features(img, wavelet='db1', level=2):\n    \"\"\"Decompose to wavelet subbands and return energy of each.\"\"\"\n    gray = cv2.cvtColor((img*255).astype(np.uint8), cv2.COLOR_BGR2GRAY)\n    coeffs = pywt.wavedec2(gray, wavelet=wavelet, level=level)\n    feats = {}\n    # coeffs[0] is approximation; coeffs[1:] are details\n    feats['wavelet_energy_approx'] = np.sum(coeffs[0]**2)\n    for i,(cH,cV,cD) in enumerate(coeffs[1:], 1):\n        feats.update({\n            f'wavelet_energy_level{i}_h': np.sum(cH**2),\n            f'wavelet_energy_level{i}_v': np.sum(cV**2),\n            f'wavelet_energy_level{i}_d': np.sum(cD**2),\n        })\n    return feats\n\ndef extract_morphological_features(img, thresh=0.5):\n    \"\"\"Binary threshold + connected components stats on lung‚Äêlike regions.\"\"\"\n    gray = cv2.cvtColor((img*255).astype(np.uint8), cv2.COLOR_BGR2GRAY)\n    # simple Otsu threshold\n    _, bw = cv2.threshold(gray, 0, 1, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    lbl = label(bw)\n    props = regionprops(lbl)\n    # area mean/std of all components\n    areas = [p.area for p in props]\n    return {\n        'comp_count': len(areas),\n        'area_mean':  np.mean(areas) if areas else 0,\n        'area_std':   np.std(areas)  if areas else 0\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:07:59.424353Z","iopub.execute_input":"2025-05-14T20:07:59.424567Z","iopub.status.idle":"2025-05-14T20:07:59.435237Z","shell.execute_reply.started":"2025-05-14T20:07:59.424551Z","shell.execute_reply":"2025-05-14T20:07:59.434527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_all_features(img):\n    feats = {}\n    feats.update(extract_radiomic_features(img))\n    feats.update(extract_gabor_features(img))\n    feats.update(extract_wavelet_features(img))\n    feats.update(extract_morphological_features(img))\n    return feats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:07:59.435960Z","iopub.execute_input":"2025-05-14T20:07:59.436148Z","iopub.status.idle":"2025-05-14T20:07:59.501355Z","shell.execute_reply.started":"2025-05-14T20:07:59.436133Z","shell.execute_reply":"2025-05-14T20:07:59.500652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# stack used + unused\nX_real = np.concatenate([X_real_used, X_real_unused], axis=0)\ny_real = np.array([1]*len(X_real_used) + [0]*len(X_real_unused))\n\n# latent vectors\nlatents = encoder.predict(X_real, batch_size=32)\ndf_latent = pd.DataFrame(latents, columns=[f'latent_{i}' for i in range(latents.shape[1])])\n\n# handcrafted features\nhc_feats = [extract_all_features(img) for img in X_real]\ndf_hc = pd.DataFrame(hc_feats)\n\n# combine\nF_real = pd.concat([df_latent, df_hc], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:07:59.502049Z","iopub.execute_input":"2025-05-14T20:07:59.502262Z","iopub.status.idle":"2025-05-14T20:08:11.419785Z","shell.execute_reply.started":"2025-05-14T20:07:59.502237Z","shell.execute_reply":"2025-05-14T20:08:11.418936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=200, random_state=42)\nclf.fit(F_real, y_real)\n\nimportances = pd.Series(clf.feature_importances_, index=F_real.columns)\ntop20 = importances.sort_values(ascending=False).head(20)\nprint(\"Top-20 features:\\n\", top20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:08:11.422063Z","iopub.execute_input":"2025-05-14T20:08:11.422289Z","iopub.status.idle":"2025-05-14T20:08:11.832107Z","shell.execute_reply.started":"2025-05-14T20:08:11.422271Z","shell.execute_reply":"2025-05-14T20:08:11.831535Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# e.g. violin plots for the top 5\nimport matplotlib.pyplot as plt\nfor i, feat in enumerate(top20.index[:5]):\n    plt.subplot(1,5,i+1)\n    data = [F_real.loc[y_real==1, feat], F_real.loc[y_real==0, feat]]\n    plt.violinplot(data)\n    plt.title(feat)\n    plt.xticks([1,2], ['used','not'])\nplt.tight_layout()\nplt.show()\n\n# UMAP on top 10\num = umap.UMAP(n_components=2, random_state=42)\nemb = um.fit_transform(F_real[top20.index[:10]])\nplt.scatter(emb[:,0], emb[:,1], c=y_real, cmap='coolwarm', alpha=0.7)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:08:11.832853Z","iopub.execute_input":"2025-05-14T20:08:11.833113Z","iopub.status.idle":"2025-05-14T20:08:18.765679Z","shell.execute_reply.started":"2025-05-14T20:08:11.833088Z","shell.execute_reply":"2025-05-14T20:08:18.765016Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compute reference distribution on ALL syn data\nall_syn = np.concatenate([\n    X_synth_train,\n    load_and_preprocess(TEST_GEN_DIR)\n], axis=0)\nsyn_feats = [extract_all_features(img) for img in all_syn]\nsyn_lat  = encoder.predict(all_syn, batch_size=32)\ndf_syn = pd.concat([\n    pd.DataFrame(syn_lat, columns=df_latent.columns),\n    pd.DataFrame(syn_feats)\n], axis=1)\n\n# Fit Mahalanobis on top-k features\ncov = EmpiricalCovariance().fit(df_syn[top20.index])\ndef maha(x): return cov.mahalanobis(x[top20.index].values.reshape(1,-1))[0]\n\n# Prepare unknowns\ndf_lat_u = pd.DataFrame(encoder.predict(X_real_unknown, batch_size=32),\n                        columns=df_latent.columns)\nhc_u = pd.DataFrame([extract_all_features(img) for img in X_real_unknown])\nF_unknown = pd.concat([df_lat_u, hc_u], axis=1)\n\n# meta-features: reconstruction error, latent-dist, maha\nrecon_u = np.mean((X_real_unknown - autoencoder.predict(X_real_unknown))**2,\n                  axis=(1,2,3))\nld_u    = cosine_distances(df_lat_u, df_syn[df_latent.columns]).min(axis=1)\nma_u    = np.array([maha(F_unknown.iloc[i]) for i in range(len(F_unknown))])\n\nmeta_u = pd.DataFrame({'recon':recon_u, 'latent_dist':ld_u, 'maha':ma_u})\n\nmeta_real = pd.DataFrame({\n    'recon': np.mean((X_real - autoencoder.predict(X_real))**2, axis=(1,2,3)),\n    'latent_dist': cosine_distances(df_latent, df_syn[df_latent.columns]).min(axis=1),\n    'maha': [maha(F_real.iloc[i]) for i in range(len(F_real))]\n})\nmeta_clf = RandomForestClassifier(n_estimators=100, random_state=42)\nmeta_clf.fit(meta_real, y_real)\n\n# predict on unknowns\ny_pred_unknown = meta_clf.predict(meta_u)\nprint(\"Predicted labels for real_unknown:\", y_pred_unknown)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:08:18.766357Z","iopub.execute_input":"2025-05-14T20:08:18.766645Z","iopub.status.idle":"2025-05-14T20:13:05.810230Z","shell.execute_reply.started":"2025-05-14T20:08:18.766614Z","shell.execute_reply":"2025-05-14T20:13:05.809445Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Predicted labels for real_unknown: [0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1\n 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0\n 1 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n 0 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1\n 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0\n 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0\n 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0\n 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0\n 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0\n 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0\n 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0]","metadata":{}},{"cell_type":"code","source":"import re\n\ndef natural_key(fname):\n    parts = re.split(r'(\\d+)', fname)\n    return [int(p) if p.isdigit() else p.lower() for p in parts]\n\nfnames = sorted(os.listdir(TEST_REAL_UNKNOWN), key=natural_key)\nrows = list(zip(fnames, y_pred_unknown))\n\ndf_sub = pd.DataFrame(rows)\ndf_sub.to_csv('run.csv', index=False, header=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:42:01.129052Z","iopub.execute_input":"2025-05-14T20:42:01.130090Z","iopub.status.idle":"2025-05-14T20:42:01.144043Z","shell.execute_reply.started":"2025-05-14T20:42:01.130062Z","shell.execute_reply":"2025-05-14T20:42:01.143044Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation\n* Since the classifier is trained on the entire training data (200 real images), it cannot again be validated on it.\n* I will use the following to validate it:\n    * Cross-validation\n    * Hold-out validation","metadata":{}},{"cell_type":"markdown","source":"# 1. Hold-out","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, cohen_kappa_score\n\n# 1. Split the 200 examples\nX_tr, X_va, y_tr, y_va = train_test_split(\n    meta_real, y_real,\n    test_size=0.3,       # 30% hold-out\n    stratify=y_real,     # keep the same used/not ratio\n    random_state=42\n)\n\n# 2. Train on 140 examples\nmeta_clf.fit(X_tr, y_tr)\n\n# 3. Evaluate on 60 unseen examples\ny_pred_va = meta_clf.predict(X_va)\nprint(\"Hold-out validation:\")\nprint(\" F1 Score      :\", f1_score(y_va, y_pred_va))\nprint(\" Cohen's Kappa :\", cohen_kappa_score(y_va, y_pred_va))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:13:05.830294Z","iopub.execute_input":"2025-05-14T20:13:05.830514Z","iopub.status.idle":"2025-05-14T20:13:05.971293Z","shell.execute_reply.started":"2025-05-14T20:13:05.830497Z","shell.execute_reply":"2025-05-14T20:13:05.970774Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Cross-validation (5-fold)","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.metrics import make_scorer, cohen_kappa_score\n\n# Wrap Cohen's Kappa so cross_val_score can use it\nkappa_scorer = make_scorer(cohen_kappa_score)\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n# F1\nf1_scores = cross_val_score(\n    meta_clf, meta_real, y_real,\n    cv=cv, scoring='f1'\n)\n\n# Cohen's Kappa\nkappa_scores = cross_val_score(\n    meta_clf, meta_real, y_real,\n    cv=cv, scoring=kappa_scorer\n)\n\nprint(\"5-Fold CV results:\")\nprint(f\" F1 Score mean      : {f1_scores.mean():.4f} ¬± {f1_scores.std():.4f}\")\nprint(f\" Cohen's Kappa mean : {kappa_scores.mean():.4f} ¬± {kappa_scores.std():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T20:13:05.971876Z","iopub.execute_input":"2025-05-14T20:13:05.972049Z","iopub.status.idle":"2025-05-14T20:13:07.297029Z","shell.execute_reply.started":"2025-05-14T20:13:05.972035Z","shell.execute_reply":"2025-05-14T20:13:07.296396Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}