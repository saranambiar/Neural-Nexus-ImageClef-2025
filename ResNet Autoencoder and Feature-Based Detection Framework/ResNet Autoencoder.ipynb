{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10846544,
          "sourceType": "datasetVersion",
          "datasetId": 6736233
        },
        {
          "sourceId": 11157226,
          "sourceType": "datasetVersion",
          "datasetId": 6961430
        },
        {
          "sourceId": 349692,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 292024,
          "modelId": 312678
        },
        {
          "sourceId": 390667,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 321754,
          "modelId": 342360
        },
        {
          "sourceId": 391804,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 322612,
          "modelId": 343300
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "autoencoder_imageclef_2",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "w7I93yYoNig7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "3zUqVOgmNig9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Preprocess the dataset\n",
        "Note: Currently not including actual dataset in the repository to maintain privacy"
      ],
      "metadata": {
        "id": "ciKu1qrRNig9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "\n",
        "IMG_SIZE = (128, 128)\n",
        "\n",
        "def load_and_preprocess_images(folder_path):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        image = load_img(img_path, target_size=IMG_SIZE)\n",
        "        image = img_to_array(image) / 255.0  # to normalise between 0&1\n",
        "        images.append(image)\n",
        "\n",
        "    return np.array(images, dtype=np.float32)\n",
        "\n",
        "\n",
        "\n",
        "synthetic_dataset = np.concatenate([synthetic_dataset_train, synthetic_dataset_test], axis=0)\n",
        "real_used_dataset = load_and_preprocess_images(\"include dataset path here\")\n",
        "real_unused_dataset = load_and_preprocess_images(\"include dataset path here\")\n",
        "\n",
        "\n",
        "print(f\"Synthetic: {synthetic_dataset.shape}\")\n",
        "print(f\"Real Used: {real_used_dataset.shape}\")\n",
        "print(f\"Real Unused: {real_unused_dataset.shape}\")\n",
        "\n",
        "X_train=synthetic_dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "fiK0w5aSNig-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Autoencoder Structure"
      ],
      "metadata": {
        "id": "lniS64uFNig-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, BatchNormalization, LeakyReLU, Add, Input,\n",
        "    Conv2DTranspose, GlobalAveragePooling2D, Dense, Reshape\n",
        ")\n",
        "\n",
        "\n",
        "def residual_block(x, filters):\n",
        "    shortcut = x\n",
        "\n",
        "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "    return x\n",
        "\n",
        "def resnet_autoencoder(input_shape=(128, 128, 3)):\n",
        "    input_img = Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    x = Conv2D(32, (3, 3), strides=2, padding='same')(input_img)\n",
        "    x = residual_block(x, 32)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), strides=2, padding='same')(x)\n",
        "    x = residual_block(x, 64)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), strides=2, padding='same')(x)\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), strides=2, padding='same')(x)\n",
        "    x = residual_block(x, 256)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    latent = Dense(512, activation='relu', name='latent')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = Dense(16 * 16 * 128, activation='relu')(latent)\n",
        "    x = Reshape((16, 16, 128))(x)\n",
        "\n",
        "    x = Conv2DTranspose(128, (3, 3), strides=2, padding='same')(x)\n",
        "    x = residual_block(x, 128)\n",
        "\n",
        "    x = Conv2DTranspose(64, (3, 3), strides=2, padding='same')(x)\n",
        "    x = residual_block(x, 64)\n",
        "\n",
        "    x = Conv2DTranspose(32, (3, 3), strides=2, padding='same')(x)\n",
        "    x = residual_block(x, 32)\n",
        "\n",
        "    output_img = Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    autoencoder = models.Model(input_img, output_img)\n",
        "    autoencoder.compile(optimizer='adam', loss='mae')\n",
        "    return autoencoder\n",
        "\n",
        "\n",
        "autoencoder_model = resnet_autoencoder()\n",
        "\n",
        "encoder_model = models.Model(\n",
        "    inputs=autoencoder_model.input,\n",
        "    outputs=autoencoder_model.get_layer('latent').output\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Autoencoder Summary:\")\n",
        "autoencoder_model.summary()\n",
        "\n",
        "print(\"\\nEncoder Summary:\")\n",
        "encoder_model.summary()\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "1ZLVLli4Nig_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "_haTDxekNig_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_model.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "IqRzwF16Nig_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_model.save('/kaggle/working/autoencoder_model.keras')"
      ],
      "metadata": {
        "trusted": true,
        "id": "KPV1pIcZNihA"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}