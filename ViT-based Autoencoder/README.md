# ViT-based Autoencoder
Autoencoders are neural networks trained to reconstruct their input. Instead of traditional CNNs, this project uses a Vision Transformer (ViT) as the encoder, showcasing the power of self-attention in unsupervised learning tasks.

?**This approach for the 2025 GANS subtask yielded the best results in terms of accuracy and Kohen-Kappa score**

Key components:
- ViT (Vision Transformer) Encoder 
- Fully-connected / CNN Decoder
- Training pipeline with metrics like accuracy and F1-score
- Visualizations of input vs. reconstructed outputs

## Repository Structure
├── ViT_based_autoencoder_.ipynb # Main Jupyter notebook

├── requirements.txt # List of dependencies

├── README.md # Project documentation

Use the following command to install the requirements:

pip install -r requirements.txt


