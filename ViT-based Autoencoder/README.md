# ViT-based Autoencoder
Autoencoders are neural networks trained to reconstruct their input. Instead of traditional CNNs, this project uses a Vision Transformer (ViT) as the encoder, showcasing the power of self-attention in unsupervised learning tasks.

Key components:
- ViT (Vision Transformer) Encoder 
- Fully-connected / CNN Decoder
- Training pipeline with metrics like accuracy and F1-score
- Visualizations of input vs. reconstructed outputs

## ğŸ“ Repository Structure
â”œâ”€â”€ ViT_based_autoencoder_.ipynb # Main Jupyter notebook
â”œâ”€â”€ requirements.txt # List of dependencies
â”œâ”€â”€ README.md # Project documentation

Use the following command to install the requirements
pip install -r requirements.txt


