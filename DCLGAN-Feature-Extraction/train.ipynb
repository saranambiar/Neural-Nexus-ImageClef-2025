{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4d3299",
   "metadata": {},
   "source": [
    "Code has been segregated for clarity of understanding. For it to be fully functional, all modules will either have to be set up as .py files, or all modules will have to be present within the same notebook. This is simply to provide understanding and structure to the working notes submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e46c5e",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models, utils\n",
    "from torchvision.models import inception_v3\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.autograd import Function\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import shutil\n",
    "import cv2\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7163072",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c41e00c",
   "metadata": {},
   "source": [
    "Gradient penalty to prevent mode collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313925c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
    "    \"\"\"Calculate gradient penalty for regularizing the discriminator\"\"\"\n",
    "    batch_size = real_samples.size(0)\n",
    "\n",
    "    # resize fake samples to match real samples if dimensions differ\n",
    "    if real_samples.shape != fake_samples.shape:\n",
    "        fake_samples = F.interpolate(fake_samples, size=real_samples.shape[2:],\n",
    "                                    mode='bilinear', align_corners=False)\n",
    "\n",
    "    # random interpolation of real and fake samples\n",
    "    alpha = torch.rand((batch_size, 1, 1, 1), device=real_samples.device)\n",
    "    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples).requires_grad_(True)\n",
    "\n",
    "    # discriminator output for interpolated images\n",
    "    d_interpolates = D(interpolates)\n",
    "\n",
    "    # calculate gradients\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(d_interpolates),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "\n",
    "    # calculate gradient penalty\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_norm = gradients.norm(2, dim=1)\n",
    "    gradient_penalty = ((gradient_norm - 1) ** 2).mean()\n",
    "\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d51e547",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4637864",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "G = Generator().to(device)\n",
    "D = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71336e2b",
   "metadata": {},
   "source": [
    "# Hyperparameter finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba52715",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, module in D.named_modules():\n",
    "    if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "        nn.utils.spectral_norm(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_loss = HULoss(bins=100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lambda_adv = 1.0\n",
    "lambda_nce = 2.0\n",
    "lambda_tv = 5e-7\n",
    "lambda_fm = 5.0\n",
    "lambda_hu = 1.0\n",
    "lambda_gp = 1.0\n",
    "n_epochs = 60\n",
    "batch_size = 256\n",
    "lr_G, lr_D = 2e-4, 2e-4\n",
    "beta1_G, beta2_G = 0.5, 0.9\n",
    "beta1_D, beta2_D = 0.5, 0.999\n",
    "\n",
    "optimizer_G = optim.Adam(G.parameters(), lr=lr_G, betas=(beta1_G, beta2_G), weight_decay=0)\n",
    "optimizer_D = optim.Adam(D.parameters(), lr=lr_D, betas=(beta1_D, beta2_D), weight_decay=0)\n",
    "\n",
    "scheduler_G = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_G, T_max=n_epochs)\n",
    "scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=50, gamma=0.5)  # slower decay for D\n",
    "\n",
    "adv_criterion = nn.BCEWithLogitsLoss()\n",
    "nce_criterion = PatchNCELoss(temperature=0.05).to(device)\n",
    "fm_loss = FeatureMatchingLoss().to(device)\n",
    "\n",
    "feat_extractor = nn.Sequential(*list(D.model.children())[:-1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"./generated_from_real_not_used\"\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607bae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_match(tensor1, tensor2):\n",
    "    if tensor1.size(2) != tensor2.size(2) or tensor1.size(3) != tensor2.size(3):\n",
    "        tensor2 = F.interpolate(tensor2, size=tensor1.shape[2:], mode='bilinear', align_corners=False)\n",
    "    return tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd31b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    epoch_g_loss = 0.0\n",
    "    epoch_d_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "    # Add DataLoader profiling\n",
    "    for i, (real_img, _) in enumerate(tqdm(dataloader_generated, desc=f\"Epoch {epoch+1}\")):\n",
    "        start = time.time()\n",
    "\n",
    "        real_img = real_img.to(device)\n",
    "        batch_size = real_img.size(0)\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate fake images\n",
    "        fake_img = G(real_img)\n",
    "\n",
    "        pred_fake = D(fake_img)\n",
    "\n",
    "        real_feats = feat_extractor(real_img)\n",
    "        fake_feats = feat_extractor(fake_img)\n",
    "\n",
    "        adv_loss = adv_criterion(pred_fake, torch.ones_like(pred_fake))\n",
    "        nce_loss = nce_criterion(real_feats, fake_feats)\n",
    "        fm_reg_loss = fm_loss([real_feats], [fake_feats])\n",
    "        hu_reg_loss = hu_loss(real_img, fake_img)\n",
    "\n",
    "        G_loss = (lambda_adv * adv_loss +\n",
    "                  lambda_nce * nce_loss +\n",
    "                  lambda_fm * fm_reg_loss +\n",
    "                  lambda_hu * hu_reg_loss)\n",
    "\n",
    "        G_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Train Discriminator\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        pred_real = D(real_img)\n",
    "        pred_fake = D(fake_img.detach())  # detach to avoid backprop through generator\n",
    "\n",
    "        real_loss = adv_criterion(pred_real, torch.ones_like(pred_real))\n",
    "        fake_loss = adv_criterion(pred_fake, torch.zeros_like(pred_fake))\n",
    "        gan_loss = (real_loss + fake_loss) * 0.5\n",
    "\n",
    "        gp = compute_gradient_penalty(D, real_img, fake_img.detach())\n",
    "\n",
    "        D_loss = gan_loss + lambda_gp * gp\n",
    "\n",
    "        D_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Track statistics\n",
    "        epoch_g_loss += G_loss.item()\n",
    "        epoch_d_loss += D_loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        # Add batch time profiling\n",
    "        torch.cuda.synchronize()  # Make sure GPU finishes before timing\n",
    "        end = time.time()\n",
    "        print(f\"Batch {i+1} time: {end - start:.2f} sec\")\n",
    "\n",
    "    # Step the learning rate schedulers\n",
    "    scheduler_G.step()\n",
    "    scheduler_D.step()\n",
    "\n",
    "    avg_g_loss = epoch_g_loss / num_batches\n",
    "    avg_d_loss = epoch_d_loss / num_batches\n",
    "\n",
    "    # Print epoch losses\n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}]\", flush=True)\n",
    "    print(f\"  G Loss: {avg_g_loss:.4f} (Adv: {adv_loss.item():.4f}, NCE: {nce_loss.item():.4f}, \"\n",
    "          f\"FM: {fm_reg_loss.item():.4f}, HU: {hu_reg_loss.item():.4f})\")\n",
    "    print(f\"  D Loss: {avg_d_loss:.4f} (GAN: {gan_loss.item():.4f}, GP: {(lambda_gp * gp).item():.4f})\")\n",
    "\n",
    "    # Save images periodically\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        G.eval()\n",
    "        with torch.no_grad():\n",
    "            test_samples = min(4, batch_size)\n",
    "            fake_img = G(real_img[:test_samples])\n",
    "\n",
    "            fake_img = (fake_img + 1) / 2.0\n",
    "            real_comp = (real_img[:test_samples] + 1) / 2.0\n",
    "\n",
    "            fake_img = resize_to_match(real_comp, fake_img)\n",
    "\n",
    "            # Save generated images\n",
    "            vutils.save_image(fake_img, os.path.join(save_dir, f\"gen_epoch_{epoch+1}.png\"), nrow=2)\n",
    "\n",
    "            # Save image comparison\n",
    "            comparison = torch.cat([real_comp, fake_img], dim=0)\n",
    "            vutils.save_image(comparison, os.path.join(save_dir, f\"compare_epoch_{epoch+1}.png\"),\n",
    "                              nrow=test_samples, normalize=False)\n",
    "\n",
    "        # Switch back to train mode\n",
    "        G.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
